---
title: "Illusion Game Validation (Study 1)"
output: html_document
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
---


```{r, echo = FALSE, warning=FALSE, message=FALSE}
options(digits = 3,
        mc.cores = 4,
        brms.algorithm = "meanfield",
        brms.backend = "cmdstanr")

cache <- FALSE
fig.width <- see::golden_ratio(7)
fig.height <- 7

knitr::opts_chunk$set(
  collapse = TRUE,
  dpi = 450,
  fig.path = "./figures/",
  fig.width = fig.width,
  fig.height = fig.height
)
```



# Introduction


The goal of study 1 was to...

# Methods


```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# PREPROCESSING ================================================================
source("preprocessing.R")

# This is a local folder containing raw data from unzipped pavlovia
# It has been added to .gitignore to NOT be published on github
# (it contains the subject ID of the participants)
participants <- list.files("study1/data/")

df <- data.frame()
for (ppt in participants) {
  df <- rbind(df, preprocess_raw(file = paste0("study1/rawdata/", ppt)))
}


df$Pyllusion <- "1.1"
df[df$Illusion_Type == "Rod-Frame", "Illusion_Strength"] <- -1 * (df[df$Illusion_Type == "Rod-Frame", "Illusion_Strength"])
df[df$Illusion_Type == "Zöllner", "Illusion_Strength"] <- -1 * round(df[df$Illusion_Type == "Zöllner", "Illusion_Strength"], 1)

# Transformation
df$Illusion_Difference_log <- log(1 + df$Illusion_Difference)
df$Illusion_Difference_sqrt <- sqrt(df$Illusion_Difference)
df$Illusion_Difference_cbrt <- round(df$Illusion_Difference**(1/3), 4)
df$Illusion_Strength_log <- sign(df$Illusion_Strength) * log(1 + abs(df$Illusion_Strength))
df$Illusion_Strength_sqrt <- sign(df$Illusion_Strength) * sqrt(abs(df$Illusion_Strength))
df$Illusion_Strength_cbrt <- sign(df$Illusion_Strength) * (abs(df$Illusion_Strength)**(1/3))

# Save anonymized data
write.csv(df, "data/study1.csv", row.names = FALSE)
```


```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggdist)
library(ggside)
library(easystats)
library(patchwork)
library(brms)

df <- read.csv("data/study1.csv") |>
  mutate(
    Date = as.Date(Date),
    Participant = fct_reorder(Participant, Date),
    Screen_Refresh = as.character(Screen_Refresh),
    Illusion_Side = as.factor(Illusion_Side),
    Block = as.factor(Block),
    Education = fct_relevel(Education, "Master", "Bachelor", "High School", "Other")
  )
```

## Exclusions {.tabset}

```{r message=FALSE, warning=FALSE}
outliers <- c(
  # Half of the trials have very short RT
  # Prolific Status: REJECTED
  "60684f29dbfe1bb2059e5e27_rkqoy",
  # Block n2 with very short RTs
  # Prolific Status: RETURNED
  "5e860198a846e30497df5189_6e43s",
  # Error rate of 46.2% and short RTs
  # Prolific Status: RETURNED
  "615f319bb341cf2f306d858d_qsaq5",
  # Error rate of 46.2%
  # Prolific Status: RETURNED
  "614f36fd81c78b7a125c4262_6ax4g",
  # Error rate of 47.9%
  # Prolific Status: REJECTED
  "61280140171ec546e87ed8cb_qdlgy",
  # Error rate of 42.1% and very large RT SD
  # Prolific Status: REJECTED
  "5d398380b37ab1000111fac3_2nxxh"
)
```

We removed `r length(outliers)` participants upon inspection of the average error rage (when close to 50%, suggesting random answers) and/or when the reaction time distribution was implausibly fast. 

For each block, we computed the error rate and, if more than 50%, we discarded the whole block (as it likely indicates that instructions got mixed up, for instance participants were selecting the smaller instead of the bigger circle).

### Error Rate

```{r message=FALSE, warning=FALSE}
dfsub <- df |>
  group_by(Participant) |>
  summarize(
    # n = n(),
    Error = sum(Error) / n(),
    RT_Mean = mean(RT),
    RT_SD = sd(RT),
  ) |>
  ungroup() |>
  arrange(desc(Error))

knitr::kable(dfsub) |> 
  kableExtra::row_spec(which(dfsub$Participant %in% outliers), background  = "#EF9A9A")
```


### Error Rate per Illusion Block

```{r message=FALSE, warning=FALSE}
temp <- df |>
  group_by(Participant, Illusion_Type, Block) |>
  summarize(ErrorRate_per_block = sum(Error) / n()) |>
  ungroup() |> 
  arrange(desc(ErrorRate_per_block))

temp2 <- temp |> 
  filter(ErrorRate_per_block >= 0.5) |> 
  group_by(Illusion_Type, Block) |> 
  summarize(n = n()) |> 
  arrange(desc(n), Illusion_Type) |> 
  ungroup() |> 
  mutate(n_trials = cumsum(n * 56),
         p_trials = n_trials / nrow(df))

# knitr::kable(temp2)

p1 <- temp |>
  estimate_density(at = c("Illusion_Type", "Block")) |>
  ggplot(aes(x = x, y = y)) +
  geom_line(aes(color = Illusion_Type, linetype = Block)) + 
  geom_vline(xintercept = 0.5, linetype = "dashed") +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  labs(y = "Distribution", x = "Error Rate") +
  theme_modern()

p2 <- temp2 |> 
  mutate(Block = fct_rev(Block)) |> 
  ggplot(aes(x = Illusion_Type, y = p_trials)) +
  geom_bar(stat="identity", aes(fill = Block)) +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_continuous(labels = scales::percent, expand = c(0, 0)) +
  labs(y = "Percentage of Trials Removed", x = "Illusion Type") +
  theme_modern() +
  theme(axis.text.x = element_text(angle=45, hjust = 1))

p1 | p2


# Drop
df <- df |>
  group_by(Participant, Illusion_Type, Block) |>
  mutate(ErrorRate_per_block = sum(Error) / n()) |>
  ungroup() |> 
  filter(ErrorRate_per_block < 0.5) |>
  select(-ErrorRate_per_block)

rm(temp, temp2)
```


### Reaction Time Distribution


```{r message=FALSE, warning=FALSE, fig.width=20, fig.height=20}
# RT distribution
p <- estimate_density(df, select = "RT", at = c("Participant", "Block")) |>
  group_by(Participant) |>
  normalize(select = "y") |>
  ungroup() |>
  mutate(color = ifelse(Participant %in% outliers, "red", "blue")) |>
  ggplot(aes(x = x, y = y)) +
  geom_area(data = normalize(estimate_density(df, select = "RT"), select = "y"), alpha = 0.2) +
  geom_line(aes(color = color, group = interaction(Participant, Block), linetype = Block)) +
  geom_vline(xintercept = 2500, linetype = "dashed", color = "red") +
  scale_color_manual(values=c("red"="red", "blue"="blue"), guide = "none") +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  coord_cartesian(xlim = c(0, 3000)) +
  theme_modern() +
  theme(axis.text.y = element_blank()) +
  facet_wrap(~Participant) +
  labs(y = "", x = "Reaction Time (ms)")
p
# ggsave("figures/outliers.png", p, width=20, height=15)

# Filter out
df <- filter(df, !Participant %in% outliers)
```

### Reaction Time per Trial

```{r message=FALSE, warning=FALSE}
p1 <- estimate_density(df, select = "RT", at = "Participant") |>
  group_by(Participant) |>
  normalize(select = "y") |>
  ungroup() |>
  ggplot(aes(x = x, y = y)) +
  geom_area(data = normalize(estimate_density(df, select = "RT"), select = "y"), alpha = 0.2) +
  geom_line(aes(color = Participant, group = Participant)) +
  geom_vline(xintercept = c(150, 3000), linetype = "dashed", color = "red") +
  scale_color_material_d("rainbow", guide = "none") +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  coord_cartesian(xlim = c(0, 3500)) +
  theme_modern() +
  theme(axis.text.y = element_blank()) +
  # facet_wrap(~Participant) +
  labs(y = "", x = "Reaction Time (ms)")


df$Outlier <- df$RT < 150 | df$RT > 3000

p2 <- df |>
  group_by(Participant) |>
  summarize(Outlier = sum(Outlier) / n()) |>
  mutate(Participant = fct_reorder(Participant, Outlier)) |>
  ggplot(aes(x = Participant, y = Outlier)) +
  geom_bar(stat = "identity", aes(fill = Participant)) +
  scale_fill_material_d("rainbow", guide = "none") +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0), labels = scales::percent) +
  see::theme_modern() +
  theme(axis.text.x = element_blank())

p1 | p2
```

We removed `r sum(df$Outlier)` (`r insight::format_value(sum(df$Outlier) / nrow(df), as_percent=TRUE)`) outlier trials (150 ms < RT < 3000 ms).

```{r message=FALSE, warning=FALSE}
df <- filter(df, Outlier == FALSE)
```




## Participants



```{r message=FALSE, warning=FALSE}
dfsub <- df |>
  group_by(Participant) |>
  select(Participant, Age, Sex, Education, Nationality, Ethnicity, Duration, Break_Duration, Screen_Resolution, Screen_Refresh, Device_OS) |>
  slice(1) |>
  ungroup()
```

The final sample included `r report::report_participants(dfsub, age="Age", sex="Sex")`.

```{r }
plot_distribution <- function(dfsub, what = "Age", title = what, subtitle = "", fill = "orange") {
  dfsub |>
    ggplot(aes_string(x = what)) +
    geom_density(fill = fill) +
    geom_vline(xintercept = mean(dfsub[[what]]), color = "red", linetype = "dashed") +
    scale_x_continuous(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0)) +
    ggtitle(title, subtitle = subtitle) +
    theme_modern() +
    theme(
      plot.title = element_text(face = "bold", hjust = 0.5),
      plot.subtitle = element_text(face = "italic", hjust = 0.5),
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      axis.text.y = element_blank()
    )
}

plot_waffle <- function(dfsub, what = "Nationality") {
  ggwaffle::waffle_iron(dfsub, what) |>
    # mutate(label = emojifont::fontawesome('fa-twitter')) |>
    ggplot(aes(x, y, fill = group)) +
    ggwaffle::geom_waffle() +
    # geom_point() +
    # geom_text(aes(label=label), family='fontawesome-webfont', size=4) +
    coord_equal() +
    ggtitle(what) +
    labs(fill = "") +
    theme_void() +
    theme(plot.title = element_text(face = "bold", hjust = 0.5))
}
```

```{r fig.width=20, fig.height=15}
p1 <- plot_distribution(dfsub, "Age", fill = "#FF9800")
p2 <- plot_distribution(dfsub, "Duration", title = "Total Duration", subtitle = "in minutes", fill = "#F44336")
p3 <- plot_distribution(dfsub, "Break_Duration", title = "Break Duration", subtitle = "in minutes", fill = "#3F51B5")

p4 <- plot_waffle(dfsub, "Sex") +
  scale_fill_manual(values = c("Male" = "#2196F3", "Female" = "#E91E63", "Other" = "#FF9800"))

p5 <- plot_waffle(dfsub, "Education") +
  scale_fill_viridis_d()

p6 <- plot_waffle(dfsub, "Nationality") +
  scale_fill_metro_d()

p7 <- plot_waffle(dfsub, "Ethnicity") +
  scale_fill_manual(values = c("Latino" = "#FF5722", "Asian" = "#FF9800", "Caucasian" = "#2196F3", "African" = "#4CAF50", "Jewish" = "#9C27B0"))

p8 <- plot_waffle(dfsub, "Screen_Resolution") +
  scale_fill_pizza_d()

p9 <- plot_waffle(dfsub, "Device_OS") +
  scale_fill_bluebrown_d()

# p10 <- plot_waffle(dfsub, "Screen_Refresh") +
#   scale_fill_viridis_d()


(p1 / p2 / p3) | (p4 / p5 / p6) | (p7 / p8 / p9)
```

## Data Analysis

The analysis of study focused on the probability of errors as the main outcome variable. For each illusion, we started by visualizing the average effect of task difficulty and illusion strength to gain some insight on the underlying generative model. Next, we tested the performance of various models differing in their specifications, such as: with or without a log-transform on the task difficulty, with or without a 2nd order polynomial term of the illusion strength, and with or without the illusion side (up *vs.* down or left *vs.* right) as an additional predictor. We then fitted the best performing model under a Bayesian model, and compared its predicted links with that of a General Additive Model (GAM), which has an increased ability of mapping underlying potentially non-linear relationships at the expense of model simplicity. Finally, we used these models to estimate different values of task difficulty that would lead to similar error rates (2.5, 5 and 25%) when the illusion strength is null.



# Results {.tabset}


```{r eval=FALSE, message=FALSE, warning=FALSE, cache=FALSE, include=FALSE}
# Exploratory 
# ============

# ISI
model <- glmmTMB::glmmTMB(Error ~ Illusion_Type * poly(ISI, 2) + (1|Participant),
                    data=mutate(df, Illusion_Type = as.factor(Illusion_Type)),
                    family="binomial")

estimate_relation(model, at = c("ISI", "Illusion_Type")) |>
  ggplot(aes(x = ISI, y = Predicted, color="Illusion_Type")) +
  geom_line()

model <- glmmTMB::glmmTMB(RT ~ Illusion_Type * poly(ISI, 2) + (1|Participant),
                    data=mutate(df, Illusion_Type = as.factor(Illusion_Type)) |>
                      filter(Error == 0))

estimate_relation(model, at = c("ISI", "Illusion_Type")) |>
  ggplot(aes(x = ISI, y = Predicted, color=Illusion_Type)) +
  geom_line()


# Difficulty - Link type
ps <- list()
for(illusion in c("Delboeuf", "Ebbinghaus", "Rod-Frame", "Poggendorff", 
"Vertical-Horizontal", "Zöllner", "Müller-Lyer", "Ponzo", 
"Contrast", "White")) {
  data <- filter(df, Illusion_Type == illusion, Illusion_Strength == 0)
  model <- mgcv::gamm(Error ~ s(Illusion_Difference, k=4),
                      random = list(Participant = ~1),
                      data=data,
                      family="binomial")

  ps[[illusion]] <- estimate_relation(model, 
                                     at = list(Illusion_Difference = unique(data$Illusion_Difference))) |>
    ggplot(aes(x = Illusion_Difference, y = Predicted)) +
    geom_bar(stat="identity", alpha=0.3) +
    geom_line() +
    ggtitle(illusion)
}

see::plots(ps)

# IES
df |> 
  group_by(Participant, Illusion_Type) |>
  summarize(Correct = 1-mean(Error)) |> 
  ungroup() |> 
  estimate_density(select="Correct") |> 
  plot()
  
df |> 
  filter(Error == 0) |> 
  group_by(Participant, Illusion_Type) |>
  summarize(RT = mean(RT)) |> 
  ungroup() |> 
  estimate_density(select="RT") |> 
  plot()
```

## Delboeuf


### Descriptive

```{r message=FALSE, warning=FALSE, cache=cache}
plot_descriptive <- function(data, side="leftright") {
  
  if(side == "leftright") {
    x <- data[data$Error == 0 & data$Illusion_Side == 1, ]$Answer[1]
    x <- tools::toTitleCase(gsub("arrow", "", x))
    if(x == "Left") {
      data$Answer <- ifelse(data$Illusion_Side == 1, "Left", "Right")
    } else if(x == "Right") {
      data$Answer <- ifelse(data$Illusion_Side == 1, "Right", "Left")
    }
  } else {
    x <- data[data$Error == 0 & data$Illusion_Side == 1, ]$Answer[1]
    x <- tools::toTitleCase(gsub("arrow", "", x))
    if(x == "Up") {
      data$Answer <- ifelse(data$Illusion_Side == 1, "Up", "Down")
    } else if(x == "Down") {
      data$Answer <- ifelse(data$Illusion_Side == 1, "Down", "Up")
    }
    data$Answer <- fct_rev(data$Answer)
  }
  
  dodge1 <- 0.1 * diff(range(data$Illusion_Difference))
  dodge2 <- -0.1 * diff(range(data$Illusion_Strength))
  
  colors <- colorRampPalette(c("#4CAF50", "#009688", "#00BCD4", "#2196F3", "#3F51B5", "#673AB7", "#9C27B0"))(length(unique(data$Illusion_Strength)))
  
  p1 <- data |> 
    group_by(Illusion_Difference, Illusion_Strength, Answer) |> 
    summarize(Error = mean(Error)) |> 
    mutate(Illusion_Strength = as.factor(round(Illusion_Strength, 2))) |> 
    ggplot(aes(x = Illusion_Difference, y = Error)) +
    geom_bar(aes(fill=Illusion_Strength), position = position_dodge(width=dodge1), stat="identity") +
    geom_line(aes(color = Illusion_Strength), position = position_dodge(width=dodge1)) +
    scale_y_continuous(limits = c(0, 1), expand = c(0, 0), labels = scales::percent) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    theme_modern() +
    labs(
      color = "Illusion Strength", 
      fill = "Illusion Strength",
      y = "Probability of Error",
      x = "Task Difficulty"
    ) +
    theme(plot.title = element_text(face = "bold", hjust = 0.5))
  
  colors <- colorRampPalette(c("#F44336", "#FFC107", "#4CAF50"))(length(unique(data$Illusion_Difference)))
    
  p2 <- data |> 
    group_by(Illusion_Difference, Illusion_Strength, Answer) |> 
    summarize(Error = mean(Error)) |> 
    mutate(Illusion_Difference = as.factor(round(Illusion_Difference, 2))) |> 
    ggplot(aes(x = Illusion_Strength, y = Error)) +
    geom_vline(xintercept=0, linetype="dotted", alpha=0.6) +
    geom_bar(aes(fill=Illusion_Difference), position = position_dodge(width=dodge2), stat="identity") +
    geom_line(aes(color = Illusion_Difference), position = position_dodge(width=dodge2)) +
    scale_y_continuous(limits = c(0, 1), expand = c(0, 0), labels = scales::percent) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    theme_modern() +
    labs(
      color = "Task Difficulty", 
      fill = "Task Difficulty",
      y = "Probability of Error",
      x = "Illusion Strength"
    ) +
    theme(plot.title = element_text(face = "bold", hjust = 0.5)) 
  
  if(side == "leftright") {
    p <- ((p1 + facet_wrap(~Answer, ncol=2, labeller = "label_both")) /
      (p2 + facet_wrap(~Answer, ncol=2, labeller = "label_both"))) + 
    plot_annotation(title = paste(data$Illusion_Type[1], "Illusion"), 
                    theme = theme(plot.title = element_text(face = "bold", hjust = 0.5)))
  } else {
    p <- ((p1 + facet_wrap(~Answer, nrow=2, labeller = "label_both")) |
      (p2 + facet_wrap(~Answer, nrow=2, labeller = "label_both"))) + 
    plot_annotation(title = paste(data$Illusion_Type[1], "Illusion"), 
                    theme = theme(plot.title = element_text(face = "bold", hjust = 0.5)))
  }
  p
}

data <- filter(df, Illusion_Type == "Delboeuf")

plot_descriptive(data)
```

### Model Selection

```{r message=FALSE, warning=FALSE, cache=cache}
best_models <- function(data) {
  models <- list()
  for(i in 1:1) {
    for(j in 1:1) {
      for(k1 in c("", "_log", "_sqrt", "_cbrt")) { 
        for(k2 in c("")) {  
          for(side in c("", "-side")) {
            name <- paste0("dif", k1, i, "-", "str", k2, j, side)
            # print(name)
            f <- paste0("poly(Illusion_Difference", 
                        k1,
                        ", ",
                        i,
                        ") * poly(Illusion_Strength",
                        k2, 
                        ", ",
                        j, 
                        ") + (1|Participant)")
            
            if(side == "-side") f <- paste0("Illusion_Side * ", f)
            
            m <- glmmTMB::glmmTMB(as.formula(paste0("Error ~ ", f)), 
                                  data = data, family = "binomial")
            if(performance::check_convergence(m)) {
              models[[name]] <- m
            }
          }
        }
      }
    }
  }

  to_keep <- compare_performance(models, metrics = c("BIC")) |> 
    arrange(BIC) |> 
    slice(1:10) |> 
    pull(Name)
  
  
  test <- test_performance(models[to_keep], reference=1)
  perf <- compare_performance(models[to_keep], metrics = c("BIC", "R2")) 
  
  merge(perf, test) |> 
    arrange(BIC) |> 
    select(Name, BIC, R2_marginal, BF) |> 
    mutate(BF = insight::format_bf(BF, name=""))
}

best_models(data)
```

### Model Visualization

```{r message=FALSE, warning=FALSE, cache=cache}
cbrt <- function(x) sign(x) * abs(x)**(1/3)

formula <- brms::bf(
  Error ~ cbrt(Illusion_Difference) * Illusion_Strength + 
    (1 | Participant),
  family = "bernoulli"
)

model <- brms::brm(formula,
  data = data,
  refresh = 0
)

# parameters::parameters(model)
```


```{r message=FALSE, warning=FALSE, cache=cache}
plot_model <- function(data, model) {
  data <- mutate(data, .dots_side = ifelse(Error == 1, "bottom", "top"))
  
  # Get variables
  vars <- insight::find_predictors(model)$conditional
  vardiff <- vars[1]
  varstrength <- vars[2]
  
  # Get predicted
  pred <- estimate_relation(model,
                            at = vars,
                            length = c(NA, 25))
  pred[[vardiff]] <- as.factor(pred[[vardiff]])
  
  # Set colors for lines
  colors <- colorRampPalette(c("#F44336", "#FFC107", "#4CAF50"))(length(unique(data[[vardiff]])))
  diffvals <- as.numeric(as.character(unique(sort(pred[[vardiff]]))))
  names(colors) <- diffvals
  
  # Assign color from the same palette to every observation of data (for geom_dots)
  closest <- diffvals[max.col(-abs(outer(data[[vars[1]]], diffvals, "-")))]
  data$color <- colors[as.character(closest)]
  data$color <- fct_reorder(data$color, closest)
  
  # Manual jittering
  xrange <- 0.05*diff(range(data[[varstrength]]))
  data$x <- data[[varstrength]]
  data$x[data$x > 0] <- data$x[data$x > 0] - runif(sum(data$x > 0), 0, xrange)
  data$x[data$x < 0] <- data$x[data$x < 0] + runif(sum(data$x < 0), 0, xrange)
  data$x[round(data$x, 2) == 0] <- data$x[round(data$x, 2) == 0] + runif(sum(round(data$x, 2) == 0), -xrange/2, xrange/2)
  
  
  pred |>
    ggplot(aes_string(x = varstrength, y = "Predicted")) +
    geom_dots(
      data = data,
      aes(x=x, y = Error, group = Error, side = .dots_side, order=color), 
      fill = data$color,
      color = NA, 
      alpha=0.5) +
    geom_slab(data=data, aes(y = Error)) +
    geom_ribbon(aes_string(ymin = "CI_low", ymax = "CI_high", fill = vardiff, group = vardiff), alpha = 0.2) +
    geom_vline(xintercept = 0, linetype = "dashed") +
    geom_hline(yintercept = c(0.05, 0.5, 0.95), linetype = "dotted", alpha = 0.5) +
    geom_line(aes_string(color = vardiff, group = vardiff)) +
    scale_y_continuous(limits = c(0, 1), expand = c(0, 0), labels = scales::percent) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    coord_cartesian(xlim=c(min(data[[varstrength]]), max(data[[varstrength]]))) +
    theme_modern() +
    labs(
      title = paste0(data$Illusion_Type[1], " Illusion"),
      color = "Difficulty", fill = "Difficulty",
      y = "Probability of Error",
      x = "Illusion Strength"
    ) +
    theme(plot.title = element_text(face = "bold", hjust = 0.5))
}

plot_model(data, model)
```



### GAM

```{r message=FALSE, warning=FALSE, cache=cache}
make_gam <- function(data) {
  
  formula <- brms::bf(
    Error ~ t2(Illusion_Difference, Illusion_Strength, bs = "cr", k=4) + 
      (1 | Participant),
    family = "bernoulli"
  )

  model <- brms::brm(formula,
    data = data,
    refresh = 0
  )
  
  list(p = plot_model(data, model), model = model)
}

gam <- make_gam(data)
gam$p
```




### Parameter Standardization



```{r message=FALSE, warning=FALSE, cache=cache}
std_params <- function(model, min=0, max=2) {
  estimate_relation(
  model,
    at = list(Illusion_Strength = c(0), 
              Illusion_Difference = seq(min, max, length.out=500)),
    ) |> 
    select(Illusion_Strength, Illusion_Difference, Error = Predicted) |> 
    slice(c(which.min(abs(Error - 0.005)), 
            which.min(abs(Error - 0.025)), 
            which.min(abs(Error - 0.25)))) |> 
    mutate(Error = insight::format_value(Error, as_percent=TRUE))
}

# range(data$Illusion_Difference)
# range(data$Illusion_Strength)

std_params(model, min=0, max=2)
std_params(gam$model, min=0, max=2)
```








## Ebbinghaus


### Descriptive

```{r message=FALSE, warning=FALSE, cache=cache}
data <- filter(df, Illusion_Type == "Ebbinghaus")

plot_descriptive(data)
```


### Model Selection

```{r message=FALSE, warning=FALSE, cache=cache}
best_models(data)
```


### Model Visualization

```{r message=FALSE, warning=FALSE, cache=cache}
formula <- brms::bf(
  Error ~ cbrt(Illusion_Difference) * Illusion_Strength + 
    (1 | Participant),
  family = "bernoulli"
)

model <- brms::brm(formula,
  data = data,
  refresh = 0
)

# parameters::parameters(model)
```

```{r message=FALSE, warning=FALSE, cache=cache}
plot_model(data, model)
```

### GAM

```{r message=FALSE, warning=FALSE, cache=cache}
gam <- make_gam(data)
gam$p
```

### Parameter Standardization



```{r message=FALSE, warning=FALSE, cache=cache}
# range(data$Illusion_Difference)
# range(data$Illusion_Strength)

std_params(model, min=0, max=2)
std_params(gam$model, min=0, max=2)
```



## Rod and Frame


### Descriptive

```{r message=FALSE, warning=FALSE, cache=cache}
data <- filter(df, Illusion_Type == "Rod-Frame")

plot_descriptive(data)

data <- filter(data, abs(Illusion_Strength) < 15)

plot_descriptive(data)
```


### Model Selection

```{r message=FALSE, warning=FALSE, cache=cache}
best_models(data)
```


### Model Visualization

```{r message=FALSE, warning=FALSE, cache=cache}
formula <- brms::bf(
  Error ~ poly(Illusion_Difference, 2) * poly(Illusion_Strength, 2) + 
    (1 | Participant),
  family = "bernoulli"
)

model <- brms::brm(formula,
  data = data,
  refresh = 0
)

# parameters::parameters(model)
```

```{r message=FALSE, warning=FALSE, cache=cache}
plot_model(data, model)
```


### GAM

```{r message=FALSE, warning=FALSE, cache=cache}
gam <- make_gam(data)
gam$p
```


### Parameter Standardization


```{r message=FALSE, warning=FALSE, cache=cache}
# range(data$Illusion_Difference)
# range(data$Illusion_Strength)

std_params(model, min=0.01, max=12)
std_params(gam$model, min=0.01, max=12)
```


## Vertical-Horizontal


### Descriptive

```{r message=FALSE, warning=FALSE, cache=cache}
data <- filter(df, Illusion_Type == "Vertical-Horizontal")

plot_descriptive(data)

data <- filter(data, abs(Illusion_Strength) < 90)

plot_descriptive(data)
```


### Model Selection

```{r message=FALSE, warning=FALSE, cache=cache}
best_models(data)
```


### Model Visualization

```{r message=FALSE, warning=FALSE, cache=cache}
formula <- brms::bf(
  Error ~ sqrt(Illusion_Difference) * Illusion_Strength + 
    (1 | Participant),
  family = "bernoulli"
)

model <- brms::brm(formula,
  data = data,
  refresh = 0
)

# parameters::parameters(model)
```

```{r message=FALSE, warning=FALSE, cache=cache}
plot_model(data, model)
```


### GAM

```{r message=FALSE, warning=FALSE, cache=cache}
gam <- make_gam(data)
gam$p
```


### Parameter Standardization


```{r message=FALSE, warning=FALSE, cache=cache}
# range(data$Illusion_Difference)
# range(data$Illusion_Strength)

std_params(model, min=0, max=0.40)
std_params(gam$model, min=0, max=0.40)
```



## Zöllner


### Descriptive

```{r message=FALSE, warning=FALSE, cache=cache}
data <- filter(df, Illusion_Type == "Zöllner")

plot_descriptive(data)

data <- filter(data, abs(Illusion_Strength) < 45)

plot_descriptive(data)
```

### Model Selection

```{r message=FALSE, warning=FALSE, cache=cache}
best_models(data)
```


### Model Visualization

```{r message=FALSE, warning=FALSE, cache=cache}
formula <- brms::bf(
  Error ~ poly(Illusion_Difference, 2) * Illusion_Strength + 
    (1 | Participant),
  family = "bernoulli"
)

model <- brms::brm(formula,
  data = data,
  refresh = 0
)

# parameters::parameters(model)
```

```{r message=FALSE, warning=FALSE, cache=cache}
plot_model(data, model)
```



### Parameter Standardization


```{r message=FALSE, warning=FALSE, cache=cache}
# range(data$Illusion_Difference)
# range(data$Illusion_Strength)

std_params(model, min=0, max=5)
```


## White


### Descriptive

```{r message=FALSE, warning=FALSE, cache=cache}
data <- filter(df, Illusion_Type == "White")

plot_descriptive(data)
```


### Model Selection

```{r message=FALSE, warning=FALSE, cache=cache}
best_models(data)
```


### Model Visualization

```{r message=FALSE, warning=FALSE, cache=cache}
formula <- brms::bf(
  Error ~ log(Illusion_Difference) * poly(Illusion_Strength, 2) + 
    (1 | Participant),
  family = "bernoulli"
)

model <- brms::brm(formula,
  data = data,
  refresh = 0
)

# parameters::parameters(model)
```

```{r message=FALSE, warning=FALSE, cache=cache}
plot_model(data, model)
```


### GAM

```{r message=FALSE, warning=FALSE, cache=cache}
gam <- make_gam(data)
gam$p
```


### Parameter Standardization


```{r message=FALSE, warning=FALSE, cache=cache}
# range(data$Illusion_Difference)
# range(data$Illusion_Strength)
# unique(data$Illusion_Strength)

std_params(model, min=0, max=20)
std_params(gam$model, min=0, max=20)
```




## Müller-Lyer

### Descriptive

```{r message=FALSE, warning=FALSE, cache=cache}
data <- filter(df, Illusion_Type == "Müller-Lyer")

plot_descriptive(data, side = "updown")
```



### Model Selection

```{r message=FALSE, warning=FALSE, cache=cache}
best_models(data)
```


### Model Visualization

```{r message=FALSE, warning=FALSE, cache=cache}
formula <- brms::bf(
  Error ~ log(Illusion_Difference) * poly(Illusion_Strength, 2) + 
    (1 | Participant),
  family = "bernoulli"
)

model <- brms::brm(formula,
  data = data,
  refresh = 0
)

# parameters::parameters(model)
```

```{r message=FALSE, warning=FALSE, cache=cache}
plot_model(data, model)
```


### GAM

```{r message=FALSE, warning=FALSE, cache=cache}
gam <- make_gam(data)
gam$p
```


### Parameter Standardization


```{r message=FALSE, warning=FALSE, cache=cache}
# range(data$Illusion_Difference)
# range(data$Illusion_Strength)

std_params(model, min=0, max=0.6)
std_params(gam$model, min=0, max=0.6)
```


## Ponzo

### Descriptive

```{r message=FALSE, warning=FALSE, cache=cache}
data <- filter(df, Illusion_Type == "Ponzo")

plot_descriptive(data, side = "updown")
```



### Model Selection

```{r message=FALSE, warning=FALSE, cache=cache}
best_models(data)
```


### Model Visualization

```{r message=FALSE, warning=FALSE, cache=cache}
formula <- brms::bf(
  Error ~ poly(Illusion_Difference, 2) * poly(Illusion_Strength, 2) + 
    (1 | Participant),
  family = "bernoulli"
)

model <- brms::brm(formula,
  data = data,
  refresh = 0
)

# parameters::parameters(model)
```

```{r message=FALSE, warning=FALSE, cache=cache}
plot_model(data, model)
```


### GAM

```{r message=FALSE, warning=FALSE, cache=cache}
gam <- make_gam(data)
gam$p
```


### Parameter Standardization


```{r message=FALSE, warning=FALSE, cache=cache}
# range(data$Illusion_Difference)
# range(data$Illusion_Strength)

std_params(model, min=0, max=20)
std_params(gam$model, min=0, max=20)
```




## Poggendorff

### Descriptive

```{r message=FALSE, warning=FALSE, cache=cache}
data <- filter(df, Illusion_Type == "Poggendorff")

plot_descriptive(data, side = "updown")

data <- filter(data, abs(Illusion_Strength) < 45)

plot_descriptive(data, side = "updown")
```



### Model Selection

```{r message=FALSE, warning=FALSE, cache=cache}
best_models(data)
```


### Model Visualization

```{r message=FALSE, warning=FALSE, cache=cache}
formula <- brms::bf(
  Error ~ log(Illusion_Difference) * poly(Illusion_Strength, 2) + 
    (1 | Participant),
  family = "bernoulli"
)

model <- brms::brm(formula,
  data = data,
  refresh = 0
)

# parameters::parameters(model)
```

```{r message=FALSE, warning=FALSE, cache=cache}
plot_model(data, model)
```


### GAM

```{r message=FALSE, warning=FALSE, cache=cache}
gam <- make_gam(data)
gam$p
```


### Parameter Standardization


```{r message=FALSE, warning=FALSE, cache=cache}
# range(data$Illusion_Difference)
# range(data$Illusion_Strength)

std_params(model, min=0, max=0.5)
std_params(gam$model, min=0, max=0.5)
```



## Contrast

### Descriptive

```{r message=FALSE, warning=FALSE, cache=cache}
data <- filter(df, Illusion_Type == "Contrast")

plot_descriptive(data, side = "updown")
```



### Model Selection

```{r message=FALSE, warning=FALSE, cache=cache}
best_models(data)
```


### Model Visualization

```{r message=FALSE, warning=FALSE, cache=cache}
formula <- brms::bf(
  Error ~ Illusion_Difference * poly(Illusion_Strength, 2) + 
    (1 | Participant),
  family = "bernoulli"
)

model <- brms::brm(formula,
  data = data,
  refresh = 0
)
```

```{r message=FALSE, warning=FALSE, cache=cache}
plot_model(data, model)
```


### GAM

```{r message=FALSE, warning=FALSE, cache=cache}
gam <- make_gam(data)
gam$p
```


### Parameter Standardization


```{r message=FALSE, warning=FALSE, cache=cache}
# range(data$Illusion_Difference)
# range(data$Illusion_Strength)

std_params(model, min=0, max=25)
std_params(gam$model, min=0, max=25)
```



# Discussion

This study allowed to elaborate a more precise prior idea regarding the magnitude of the effects at stake and the type of interaction between them. Crucially, it allowed us to refine the range of task difficulty and illusion strength for the stimuli of the next study to maximize the information gain.

One thing that stood out was Zöller, which seems to exhibit a non-linear relationship of illusion effect. Next study, by generating a wider range of illusion strength, will attempt at clarifying this point.

Perceptual decisions often exhibit a non-linear relationship with the objective physical values (e.g., a logarithmic relationship. In order to spread the difficulty levels based on the behavioral performance (to maximize the diversity of the stimuli in regards to perceptual processes), we generated, for study 2, stimuli with the difficulty levels spaced non-linearly, depending on the best underlying model (i.e., with an exponential, square or cubic spacing if the best model was *log*, *square root* or *cube root*). For instance, a linear space of [0.1, 0.3, 0.5, 0.7] can be transformed to an exponential space of [0.1, 0.27, 0.47, 0.7].
